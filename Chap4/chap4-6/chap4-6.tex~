\documentclass[notheorems,mathserif,table,compress]{beamer}  %dvipdfm选项是关键,否则编译统统通不过
%%------------------------常用宏包------------------------
%%注意, beamer 会默认使用下列宏包: amsthm, graphicx, hyperref, color, xcolor, 等等
\usepackage{fontspec,xunicode,xltxtra}
\usepackage{amsfonts,amssymb}  % for XeTeX
%%------------------------ThemeColorFont------------------------
%% Presentation Themes
% \usetheme[<options>]{<name list>}
\usetheme{Madrid}
%% Inner Themes
% \useinnertheme[<options>]{<name>}
%% Outer Themes
% \useoutertheme[<options>]{<name>}
\useoutertheme{miniframes} 
%% Color Themes 
% \usecolortheme[<options>]{<name list>}
%% Font Themes
% \usefonttheme[<options>]{<name>}
\setbeamertemplate{background canvas}[vertical shading][bottom=white,top=structure.fg!7] %%背景色, 上25%的蓝, 过渡到下白.
\setbeamertemplate{theorems}[numbered]
\setbeamertemplate{navigation symbols}{}   %% 去掉页面下方默认的导航条.
\usepackage{zhfontcfg}
\usepackage{iplouclistings}
%\setsansfont[Mapping=tex-text]{文泉驿正黑}  %% 需要fontspec宏包
     %如果装了Adobe Acrobat,可在font.conf中配置Adobe字体的路径以使用其中文字体
     %也可直接使用系统中的中文字体如SimSun,SimHei,微软雅黑 等
     %原来beamer用的字体是sans family;注意Mapping的大小写,不能写错
     %设置字体时也可以直接用字体名，以下三种方式等同：
     %\setromanfont[BoldFont={黑体}]{宋体}
     %\setromanfont[BoldFont={SimHei}]{SimSun}
     %\setromanfont[BoldFont={"[simhei.ttf]"}]{"[simsun.ttc]"}
%%------------------------MISC------------------------
\graphicspath{{figures/}}         %% 图片路径. 本文的图片都放在这个文件夹里了.
%%------------------------正文------------------------
\begin{document}
\XeTeXlinebreaklocale "zh"         % 表示用中文的断行
\XeTeXlinebreakskip = 0pt plus 1pt % 多一点调整的空间
%%----------------------------------------------------------
%% This is only inserted into the PDF information catalog. Can be left
%% out.
%%%
%% Delete this, if you do not want the table of contents to pop up at
%% the beginning of each subsection:
\AtBeginSection[]{                              % 在每个Section前都会加入的Frame
  \frame<handout:0>{
    \frametitle{内容提要}\small
    \tableofcontents[current,currentsubsection]
  }
}
\AtBeginSubsection[]                            % 在每个子段落之前
{
  \frame<handout:0>                             % handout:0 表示只在手稿中出现
  {
    \frametitle{下一节内容}\small
    \tableofcontents[current,currentsubsection] % 显示在目录中加亮的当前章节
  }
}
%%----------------------------------------------------------
\title[Numerical Analysis]{Numerical Analysis}
\subtitle{Mathematics of Scientific Computing}
\author[sun]{主讲人~~~~~\textcolor{olive}{孙晓庆}\\
    \quad 幻灯片制作~~\textcolor{olive}{孙晓庆}}
\institute[中国海洋大学]{\small\textcolor{violet}{中国海洋大学~~信息科学与工程学院}}
\date{2013~年~10~月~11~日}
%\titlegraphic{\vspace{-6em}\includegraphics[height=7cm]{ouc}\vspace{-6em}}
\frame{ \titlepage }
%%----------------------------------------------------------
\section*{目录}
\frame{\frametitle{目录}\tableofcontents}
%%----------------------------------------------------------
\section{Solution of Equations by Iterative Methods}
\subsection{4.6.1 Basic Concepts}%如果你想书签不出现问题,请不要用\XeTeX
                                 %这类复杂的指令,直接写XeTeX吧
\begin{frame}
A general type of iterative process for solving the system $Ax=b$\\
A certain matrix $Q$, called the \textbf{splitting matrix},\\
\begin{displaymath}
Qx=(Q-A)x+b
\end{displaymath}
\begin{displaymath}
Qx^{(k)}=(Q-A)x^{(k-1)}+b
\end{displaymath}
\begin{displaymath}
x^{(k)}=(I-Q^{-1}A)x^{(k-1)}+Q^{-1}b
\end{displaymath}
Our objective is to choose $Q$ so that these two conditions are met:\\
$1$. The sequence $[x^{(k)}]$ is easily computed.\\
$2$. The sequence $[x^{(k)}]$ converges rapidly to a solution.
\end{frame}



       
% \XeTeXpicfile "./logo.jpg" xscaled 100 yscaled 100 %插图也没有问
\begin{frame}
\theoremstyle{plain}
\newtheorem{theorem}{THEOREM}
\begin{theorem}[Theorem on Iterative Method Convergence]
If $\parallel I-Q^{-1}A \parallel<1$ for some subordinate matrix norm, then the sequence produced by the  Equation $Qx^{(k)}=(Q-A)x^{(k-1)}+b$ converges to the solution of $Ax=b$ for any initial vector $x^{(0)}$.
\end{theorem}

\begin{proof}
Since $\parallel I-Q^{-1}A \parallel<1$, $A$ and $Q$ are nonsingular.\\
$x^{(k)}=(I-Q^{-1}A)x^{(k-1)}+Q^{-1}b$\\
The actual solution $x$ satisfies the equation $x=(I-Q^{-1}A)x+Q^{-1}b$\\
$x^{(k)}-x=(I-Q^{-1}A)(x^{(k-1)}-x)$\\
$\parallel x^{(k)}-x \parallel \leq\parallel (I-Q^{-1}A)\parallel \parallel (x^{(k-1)}-x)\parallel$\\
$\parallel x^{(k)}-x \parallel \leq\parallel(I-Q^{-1}A)\parallel^{k} \parallel(x^{(0)}-x)\parallel$\\
Since $\parallel I-Q^{-1}A \parallel<1$ We can conclude that $\lim_{k \to \infty}\parallel x^{(k)}-x\parallel=0$
\end{proof}
\end{frame}

\subsection{4.6.2 Richardson Method}
\begin{frame}
$Q$ is chosen to be the identity matrix. The equation $Qx^{(k)}=(Q-A)x^{(k-1)}+b$ in this case read as follows:\\
\begin{displaymath}
x^{(k)}=(I-A)x^{(k-1)}+b=x^{(k-1)}+r^{(k-1)}
\end{displaymath}
where $r^{(k-1)}$ is the residual vector, $r^{(k-1)}=b-Ax^{(k-1)}$. If $\parallel I-A\parallel<1$ for some subordinate matrix norm, the Richardson iteration will produce a solution to $Ax=b$.
\end{frame}

\begin{frame}
An algorithm of Richardson iteration is as follows:\\
input $n$, $(a_{ij})$, $(b_{i})$, $(x_{i})$, $M$\\
for $k=1$ to $M$ do\\
for $i=1$ to $n$ do\\
$r_{i} \leftarrow b_{i}-\sum_{j=1}^n a_{ij}x_{j}$\\
end do\\
for $i=1$ to $n$ do\\
$x_{i} \leftarrow x_{i}+r_{i}$\\
end do\\
end do\\
output $k$, $(x_{i})$, $(r_{i})$
\end{frame}


\begin{frame}
\lstinputlisting{./Richardson/richardson.m}
\end{frame}

\subsection{4.6.3 Jacobi Method}
\begin{frame}
$Q$ is the diagonal matrix whose diagonal entries are the same as those in the matrix $A=(a_{ij})$. $Q^{-1}A$ is $a_{ij}/a_{ii}$, and hence
\begin{displaymath}
\parallel I-Q^{-1}A \parallel_{\infty}=\max_{1\leq i\leq n}\sum_{\begin{subarray}{l}
{j=1}\\j\neq i
\end{subarray}}^n|a_{ij}/a_{ii}|
\end{displaymath}
\end{frame}

\begin{frame}
\begin{theorem}[Theorem on Convergence of Jacobi Method]
If $A$ is diagonally dominant, then the sequence produced by the Jacobin iteration converges to the solution of $Ax=b$ for any staring vector.
\end{theorem}
\begin{proof}
Diagonal dominance means that
\begin{displaymath} 
|a_{ii}|>\sum_{\begin{subarray}{l}
{j=1}\\j\neq i
\end{subarray}}^n|a_{ij}| \qquad (1\leq i \leq n)
\end{displaymath}
\begin{displaymath}
\parallel I-Q^{-1}A \parallel_{\infty}=\max_{1\leq i\leq n}\sum_{\begin{subarray}{l}
{j=1}\\j\neq i
\end{subarray}}^n|a_{ij}/a_{ii}|
\end{displaymath}
We then conclude that $\parallel I-Q^{-1}A \parallel_{\infty}<1$.\\
By Theorem $1$, the Jacobi iteration converges.
\end{proof}
\end{frame}

\begin{frame}
%An algorithm for the Jacobi method follows:\\
input $n$, $(a_{ij})$, $(b_{i})$, $(x_{i})$, $M$\\
for $k=1$ to $M$ do\\
%\quad for $i=1$ to $n$ do\\
%\quad $d=1/a_{ii}$\\
%\quad $b(i)\leftarrow db(i)$\\
%\quad for $j=1$ to $n$ do\\
%\quad $a(ij)=da(ij)$\\
%\quad end do\\
%\quad end do\\

\quad for $i=1$ to $n$ do\\
\quad $u_{i}\leftarrow (b_{i}-\sum_{\begin{subarray}{l}
{j=1}\\j\neq i
\end{subarray}}^n a_{ij}x_{j})/a(ii)$\\
\quad end do\\
\quad for $i=1$ to $n$ do\\
\quad$x_{i}\leftarrow u_{i}$\\
\quad end do\\
\quad output $k$, $(x_{i})$\\
end do
\end{frame}

\begin{frame}
\lstinputlisting{./jacobi/jacobi.m}
\end{frame}


\subsection{4.6.4 Analysis}
\begin{frame}
\frametitle{Basic Concepts}
\begin{itemize}
\item For arbitrary linear iterative processes. $x^{(k)}=Gx^{(k-1)}+c$, we set $G=I-Q^{-1}A$ and $c=Q^{-1}b$.
\item The \textbf{characteristic equation} of $A$: $det(A-\lambda I)=0$\\
\item The \textbf{spectral radius} of $A$: $\rho(A)=\max\{|\lambda|:det(A-\lambda I)=0\}$
\item If $S^{-1}AS=B$, the similar matrices matrices have the same eigenvalues.
\end{itemize}
\end{frame}

\begin{frame}
\begin{theorem}[Theorem on Similar Upper Trigngular Matrices]
Every square matrix is similar to an (possibly complex) upper triangular matrix whose off-diagonal elements are arbitrarily small.
\end{theorem}
\begin{proof}
Let $A$ be an $n\times n$ matrix. Schur's theoerm states that $A$ is similar to an upper triangular matrix $T=(t_{ij})$, which may be complex. Let $D=diag(\varepsilon
,\varepsilon^{2},...,\varepsilon^{n})$. The generic element of $B=D^{-1}TD$ is $t_{ij}\varepsilon^{j-i}$. The elements above the diagonal can be made as small as
 we   wish by decreasing $\varepsilon$.
\end{proof}
\end{frame}

\begin{frame}
\begin{theorem}[Theorem on Spectral Radius]
The spectral radius function safisfies the equation 
\begin{displaymath}
\rho(A)=inf_{\begin{subarray}{l}
{\parallel \cdot\parallel}
\end{subarray}}\parallel A \parallel
\end{displaymath}
in which the infimum is take over all subordinate matrix norms.
\end{theorem}
\begin{proof}
First, we prove that $\rho(A)\leq inf_{\begin{subarray}{l}
{\parallel\cdot \parallel}
\end{subarray}}\parallel A \parallel$\\
Let $\lambda$ be any eigenvalue of $A$. Select a nonzero eigenvector $x$ corresponding to $\lambda$.\\
$|\lambda|\parallel x \parallel=\parallel \lambda x\parallel=\parallel Ax\parallel \leq \parallel A\parallel \parallel x\parallel$ \\
$|\lambda|\leq \parallel A\parallel$. We have   $\rho(A)\leq inf_{\begin{subarray}{l}
{\parallel\cdot \parallel}
\end{subarray}}\parallel A \parallel$\\
\end{proof}
\end{frame}

\begin{frame}
\begin{proof}
Second, we prove that $ inf_{\begin{subarray}{l}
{\parallel\cdot\parallel}
\end{subarray}}\parallel A \parallel \leq \rho(A) $\\
For the reverse inequality, we use Theorem $3$. We have \\
$\parallel S^{-1}AS \parallel_{\infty}=\parallel D+T \parallel_{\infty} \leq \parallel D\parallel_{\infty} + \parallel T\parallel_{\infty}$\\
Since $D$ has the eigenvalues of $A$ on its diagonal, it follows that\\
$\parallel D \parallel_{\infty}=\max_{1\leq i\leq n}|\lambda|=\rho(A)$\\
$\parallel S^{-1}AS \parallel_{\infty}\leq \rho(A)+\varepsilon$\\
$\parallel A \parallel^{'}_{\infty}=\parallel S^{-1}AS \parallel_{\infty}$\\
$inf_{\begin{subarray}{l}
{\parallel \cdot\parallel}
\end{subarray}}\parallel A \parallel \leq \rho(A) +\varepsilon$\\
$inf_{\begin{subarray}{l}
{\parallel\cdot \parallel}
\end{subarray}}\parallel A \parallel \leq \rho(A) $\\
So $\rho(A)=inf_{\begin{subarray}{l}
{\parallel \cdot\parallel}
\end{subarray}}\parallel A \parallel$
\end{proof}
\end{frame}


\begin{frame}
\begin{theorem}[Theorem on Necessary and Sufficient Conditions for Iterative Method Convergence]
For the iteration formual $x^{(k)}=Gx^{(k-1)}+c$ to produce a sequence converging to $(I-G)^{-1}c$, for any starting vector $x^{(0)}$, it is necessary and sufficient that the spectral radius of $G$ be less than $1$.
\end{theorem}
\begin{proof}
First, Suppose that $\rho(G)<1$. There is a subordinate matrix norm such that $\parallel G \parallel < 1$. We write\\
$x^{(1)}=Gx^{(0)}+c$\\
$x^{(2)}=G^{2}x^{(0)}+Gc+c$\\
$x^{(3)}=G^{3}x^{(0)}+G^{2}c+Gc+c$\\
The general formula is $x^{(k)}=G^{k}x^{(0)}+\sum_{j=0}^{k-1} G^{j}c$
$\parallel G^{k}x^{(0)} \parallel \leq \parallel G^{k} \parallel \parallel x^{(0)} \parallel  \leq \parallel G \parallel^{k} \parallel x^{(0)} \parallel \rightarrow 0$
as $k \rightarrow  {\infty}$\\
We have $\sum_{k=1}^{\infty}G^{j}c=(I-G)^{-1}c$\\
$\lim_{k \to \infty} x^{(k)}=(I-G)^{-1}c$
\end{proof}
\end{frame}

\begin{frame}
\begin{proof}
Second, suppose that $\rho(G)\geq 1$.\\
 Select $u$ and $\lambda$, so that $Gu=\lambda u$ \quad $|\lambda|\geq 1$ \quad $u\neq 0$.\\ Let $c=u$ and $x^{(0)}=0$.\\ By the Equation $x^{(k)}=G^{k}x^{(0)}+\sum_{j=0}^{k-1} G^{j}c$,\\ $x^{(k)}=\sum_{j=0}^{k-1} G^{j}u=\sum_{j=0}^{k-1}\lambda^{j}u$.\\ If $\lambda=1$, $x^{(k)}=ku$, and this diverges as $k\rightarrow \infty$.\\ If $\lambda \neq 1$, then $x^{(k)}=(\lambda^{k}-1)(\lambda-1)^{-1}u$, and this diverges also because $\lim_{k \to \infty}\lambda^{k}$ does not exist.
\end{proof}
\end{frame}


\begin{frame}
\theoremstyle{plain}
\newtheorem{corollapy}{COROLLARY}
\begin{corollapy}[Iterative Method Convergence Corollary]
The iteration formual $Qx^{(k)}=(Q-A)x^{(k-1)}+b$, will produce a sequence converging to the solution of $Ax=b$, for any $x^{(0)}$, if $\rho(I-Q^{-1}A)<1$
\end{corollapy}
\end{frame}

\subsection{4.6.5 Gauss-Seidel Method}
\begin{frame}
\begin{itemize}
\item Let us examine Gauss-Seidel iteration in more detail. It is defined by letting $Q$ be the lower triangular part of $A$, including the diagonal.\\
\item An algorithm for the Gauss-Seidel iteration follows:\\
input $n$, $(a_{ij})$, $(b_{i})$, $(x_{i})$, $M$\\
for $k=1$ to $M$ do\\
for $i=1$ to $n$ do\\
$x_{i}\leftarrow (b_{i}-\sum_{\begin{subarray}{l}
{j=1}\\j\neq i
\end{subarray}}^n a_{ij}x_{j})/a_{ii}$\\
end do\\
output $k$, $(x_{i})$\\
end do
\end{itemize}
\end{frame}

\begin{frame}
\begin{theorem}[Theorem on Gauss-Seidel Method Convergence]
If $A$ is diagonally dominant, then the Gauss-Seidel method converges for any starting vector.
\end{theorem}
\end{frame}

\begin{frame}
\begin{proof}
By Corollary $1$, it suffices to prove that $\rho(I-Q^{-1}A)<1$. To this end, let $\lambda$ be any eigenvalue of $I-Q^{-1}A$. Let $x$ be a corresponding eigenvector. We assume, that  $\parallel x \parallel_{\infty}=1$. We have now 
$(I-Q^{-1}A)x=\lambda x$ \quad or\quad $Qx-Ax=\lambda Qx$.\\
Since $Q$ is the lower triangular part of $A$, including its diagonal,\\
\begin{displaymath}
 -\sum_{j=i+1}^{n}a_{ij}x_{j}=\lambda\sum_{j=1}^{i}a_{ij}x_{j} \qquad (1\leq i\leq n)
\end{displaymath}
\begin{displaymath}
\lambda a_{ii}x_{i}=-\lambda \sum_{j=1}^{i-1}a_{ij}x_{j}-\sum_{j=i+1}^{n}a_{ij}x_{j} \qquad (1\leq i\leq n)
\end{displaymath}
Select an index $i$ such that $|x_{i}|=1\geq |x_{j}|$ for all $j$. Then, $|\lambda| |a_{ii}| \leq |\lambda| \sum_{j=1}^{i-1}|a_{ij}|+\sum_{j=i+1}^{n}|a_{ij}|$ \\
 $|\lambda| \leq \{\sum_{j=i+1}^{n}|a_{ij}|\}\{|a_{ij}|-\sum_{j=1}^{i-1} |a_{ij}|\}^{-1}<1$
\end{proof}
\end{frame}




\subsection{4.6.6 SOR Method}
\begin{frame}
\frametitle{Basic Concepts}
In the space of complex $n$$-$vectors.
\begin{itemize}
\item The \textbf{conjugate transpose} of $y$, $y^{*}={(\bar{y_{1}}, \bar{y_{2}},...,\bar{y_{n}})}$
\item The \textbf{inner product} $\langle x,y \rangle=y^{*}x=\sum_{i=1}^{n}x_{i}\bar{y_{i}}$
\item $\langle x, x \rangle>0$ \qquad (if $x\neq 0$)\\
 $\langle x,\lambda y \rangle=\bar{\lambda}\langle x, y \rangle$\\
$\langle x, y \rangle=\overline{\langle y, x \rangle}$
\item The \textbf{conjugate transpose} of $A$, $A^{*}=(\bar{a_{ji}})$
\item \textbf{Hermitian:}  $A^{*}=A$
\item If $A$ is Hermitian, then $\langle Ax,y \rangle= \langle x, Ay \rangle$
\end{itemize}
\end{frame}

\begin{frame}
\begin{theorem}[Theorem on SOR Method Convergence]
In the SOR method, suppose that splitting matrix $Q$ is chosen to be $\alpha D-C$, where $\alpha$ is a real parameter, $D$ is any positive definite Hermitian matrix, and $C$ is any matrix safisfying $C+C^{*}=D-A$. If $A$ is positive definite Hermitian, if $Q$ is nonsigular, and if $\alpha>1/2$, then the SOR iteration converges for any starting vector.
\end{theorem}
\end{frame}

\begin{frame}
\begin{proof}
We let $G=I-Q^{-1}A$ and attempt to establish that the spectal radius of $G$ satisfies $\rho(G)<1$. Let $Gx=\lambda x$, and $y=(I-G)x$.\\
\begin{displaymath}
y=x-Gx=x-\lambda x=Q^{-1}Ax
\end{displaymath}
\begin{displaymath}
Q-A=(\alpha D-C)-(D-C-C^{*})=\alpha D-D+C^{*}
\end{displaymath}
We have 
\begin{equation}
%\begin{displaymath}
(\alpha D-C)y=Qy=Ay
\end{equation}
%\end{displaymath}
%\begin{displaymath}
\begin{equation}
 (D-C-C^{*})y=AGx
\end{equation}
%\end{displaymath}
%\begin{displaymath}
\begin{equation}
\alpha\langle Dy,y \rangle-\langle Cy,y \rangle=\langle Ax,y \rangle
\end{equation}
%\end{displaymath}
%\begin{displaymath}
\begin{equation}
\alpha\langle y,Dy \rangle-\langle y,Dy \rangle+\langle y,C^{*}y \rangle=\langle y,AGx \rangle
\end{equation}
%\end{displaymath}
On adding Equations$(3)$ and $(4)$, We obtain\\
%\begin{displaymath}
\begin{equation}
2\alpha\langle Dy,y \rangle-\langle y,Dy \rangle=\langle Ax,y \rangle+\langle y,AGx \rangle
\end{equation}
%\end{displaymath}
\begin{displaymath}
(2\alpha-1)\langle Dy,y \rangle=\langle Ax,y \rangle=\langle Ax,y \rangle=\langle y,AGx \rangle
\end{displaymath}
\end{proof}
\end{frame}

\begin{frame}
\begin{proof}
\begin{displaymath}
(2\alpha-1)\langle Dy,y \rangle=\langle Ax,y \rangle+\langle y,AGx \rangle
\end{displaymath}
Since $y=(1-\lambda)x$ and $Gx=\lambda x$, Equation$(5)$ yields\\
\begin{equation}
%\begin{displaymath}
(2\alpha-1)|1-\lambda|^{2}\langle Dx,x \rangle=(1-\bar{\lambda})\langle Ax,x \rangle+\bar{\lambda}(1-\lambda)\langle x,Ax \rangle=(1-|\lambda|^{2})\langle Ax,x \rangle
\end{equation}
%\end{displaymath}
If $\lambda \neq 1$, the left side of the equation $(6)$ is positive. Hence, the right side must also be positive, and $|\lambda|<1$.\\
On the other hand, if $\lambda=1$, then $y=0$ from $y=(1-\lambda)x$ and $Ax=0$. This contradicts the condition $\langle Ax,x \rangle>0$ for any $x\neq 0$.\\
Thence, $\rho(G)<1$ and the SOR method converges.
\end{proof}
A common choice for $D$ and $C$ in the SOR method is to let $D$ be the diagonal of $A$ and $-C$ be the lower triangular part of $A$, excluding the diagonal.
\end{frame}


\subsection{4.6.7 Iteration Matrices}
\begin{frame}
Suppose that $A$ is partitioned into $A=D-C_{L}-C_{U}$, where $D=diag(A)$, $C_{L}$ is the negitive of the  strictly lower triangular part of $A$, and $C_{U}$ is the negitive of the stictly upper triangular part of $A$.\\
$Qx^{(k)}=(Q-A)x^{(k-1)}+b$\\
$x^{(k)}=(I-Q^{-1}A)x^{(k-1)}+Q^{-1}b$\\
$G=I-Q^{-1}A$\\
\textbf{Richardson}:
\begin{displaymath}
\left\{ \begin{array}{ll}
Q=I\\
G=I-A
\end{array} \right.
\end{displaymath}
\begin{displaymath}
x^{(k)}=(I-A)x^{(k-1)}+b
\end{displaymath}
\end{frame}


\begin{frame}
\textbf{Jacobi}
\begin{displaymath}
\left\{ \begin{array}{ll}
Q=D\\
G=D^{-1}(C_{L}+C_{U})
\end{array} \right.
\end{displaymath}
\begin{displaymath}
Dx^{(k)}=(C_{L}+C_{U})x^{(k-1)}+b
\end{displaymath}

\textbf{Gauss-Seidel}
\begin{displaymath}
\left\{ \begin{array}{ll}
Q=D-C_{L}\\
G=(D-C_{L})^{-1}C_{U}
\end{array} \right.
\end{displaymath}
\begin{displaymath}
(D-C_{L})x^{(k)}=C_{U}x^{(k-1)}+b
\end{displaymath}



\textbf{SOR}
\begin{displaymath}
\left\{ \begin{array}{ll}
Q=\omega^{-1} (D-\omega C_{L})\\
G=(D-\omega C_{L})^{-1}(\omega C_{U}+(1-\omega)D)
\end{array} \right.
\end{displaymath}
\begin{displaymath}
(D-\omega C_{L})x^{(k)}=\omega (C_{U}x^{(k-1)}+b)+(1-\omega)Dx^{(k-1)}
\end{displaymath}
\end{frame}


\subsection{4.6.8 Extrapolation}

\begin{frame}
Consider the iteration formula $x^{(k)}=Gx^{(k-1)}+c$\\
We introduce a parameter $\gamma \neq 0$ and embedded in a one-parameter family of iteration methods given by\\
\begin{displaymath}
x^{(k)}=\gamma (Gx^{(k-1)}+c)+(1-\gamma)x^{(k-1)}=G_{\gamma}x^{k-1}+\gamma c
\end{displaymath}
where 
\begin{displaymath}
G_{\gamma}=\gamma G+(1-\gamma)I
\end{displaymath}
Then by taking a limit, we get $x=\gamma(Gx+c)+(1-\gamma)x$ or $x=Gx+c$.
\end{frame}



\begin{frame}
\begin{theorem}[Theorem on Eigenvalue of $p(A)$]
If $\lambda$ is an eigenvalue of a matrix $A$ and if $p$ is a polynomial, then $p(\lambda)$ is an eigenvalue of $p(A)$.
\end{theorem}
\begin{proof}
Let $Ax=\lambda x$ with $x \neq 0$. Then $A^{2}x=\lambda Ax=\lambda^{2}x$, we have
\begin{displaymath}
A^{k}x=\lambda ^{k}x
\end{displaymath}
\begin{displaymath}
p(A)x=\sum_{k=0}^{m}c_{k}A^{k}x=\sum_{k=0}^{m}c_{k}\lambda^{k}x=p(\lambda)x
\end{displaymath}
\end{proof}
\end{frame}


\begin{frame}
\begin{theorem}[Theorem on Optimal Extrspolation Parameters]
If the only information avaliable about the eigenvalues of $G$ is that they lie in the interval $[a,b]$, and if $1\notin[a,b]$, then the best choice for $\gamma $ is $2/(2-a-b)$. With this value of $\gamma $, $\rho(G_{\gamma})\leq 1-|\gamma|d$, where $d$ is the distance from $1$ to $[a,b]$
\end{theorem}
\end{frame}


\begin{frame}
\begin{proof}
The eigenvalues of $G$ in an interval $[a,b]$\\
The eigenvalues of $G_{\gamma}=\gamma G+(1-\gamma)I$ in the interval $[\gamma a+1-\gamma, \gamma b+1-\gamma]$\\
Since $1\notin[a,b]$, $a>1$ or $b<1$\\
Since $a\leq b<1$, it follows that $\gamma >0$ and $d=1-b$.\\
$\gamma a+1-\gamma \leq \lambda \leq \gamma b+1-\gamma$\\
$\lambda \leq \gamma b+1-\gamma=1+\gamma(b-1)=1-\gamma d$\\
$\lambda \geq \gamma a+1-\gamma=\gamma(a+b-2)+1+\gamma(1-b)=-1+\gamma d$\\
We have proved that $-1+\gamma d \leq \lambda \leq 1-\gamma d$
\end{proof}
\end{frame}














\end{document}
