\documentclass[notheorems,mathserif,table,compress]{beamer}  %dvipdfm选项是关键,否则编译统统通不过
%%------------------------常用宏包------------------------
%%注意, beamer 会默认使用下列宏包: amsthm, graphicx, hyperref, color, xcolor, 等等
\usepackage{fontspec,xunicode,xltxtra}
\usepackage{amsfonts,amssymb}  % for XeTeX
%%------------------------ThemeColorFont------------------------
%% Presentation Themes
% \usetheme[<options>]{<name list>}
\usetheme{Madrid}
%% Inner Themes
% \useinnertheme[<options>]{<name>}
%% Outer Themes
% \useoutertheme[<options>]{<name>}
\useoutertheme{miniframes} 
%% Color Themes 
% \usecolortheme[<options>]{<name list>}
%% Font Themes
% \usefonttheme[<options>]{<name>}
\setbeamertemplate{background canvas}[vertical shading][bottom=white,top=structure.fg!7] %%背景色, 上25%的蓝, 过渡到下白.
\setbeamertemplate{theorems}[numbered]
\setbeamertemplate{navigation symbols}{}   %% 去掉页面下方默认的导航条.
\usepackage{zhfontcfg}
\usepackage{iplouclistings}
%\setsansfont[Mapping=tex-text]{文泉驿正黑}  %% 需要fontspec宏包
     %如果装了Adobe Acrobat,可在font.conf中配置Adobe字体的路径以使用其中文字体
     %也可直接使用系统中的中文字体如SimSun,SimHei,微软雅黑 等
     %原来beamer用的字体是sans family;注意Mapping的大小写,不能写错
     %设置字体时也可以直接用字体名，以下三种方式等同：
     %\setromanfont[BoldFont={黑体}]{宋体}
     %\setromanfont[BoldFont={SimHei}]{SimSun}
     %\setromanfont[BoldFont={"[simhei.ttf]"}]{"[simsun.ttc]"}
%%------------------------MISC------------------------
\graphicspath{{figures/}}         %% 图片路径. 本文的图片都放在这个文件夹里了.
%%------------------------正文------------------------
\begin{document}
\XeTeXlinebreaklocale "zh"         % 表示用中文的断行
\XeTeXlinebreakskip = 0pt plus 1pt % 多一点调整的空间
%%----------------------------------------------------------
%% This is only inserted into the PDF information catalog. Can be left
%% out.
%%%
%% Delete this, if you do not want the table of contents to pop up at
%% the beginning of each subsection:
\AtBeginSection[]{                              % 在每个Section前都会加入的Frame
  \frame<handout:0>{
    \frametitle{内容提要}\small
    \tableofcontents[current,currentsubsection]
  }
}
\AtBeginSubsection[]                            % 在每个子段落之前
{
  \frame<handout:0>                             % handout:0 表示只在手稿中出现
  {
    \frametitle{下一节内容}\small
    \tableofcontents[current,currentsubsection] % 显示在目录中加亮的当前章节
  }
}
%%----------------------------------------------------------
\title[Numerical Analysis]{Numerical Analysis}
\subtitle{Mathematics of Scientific Computing}
\author[sun]{主讲人~~~~~\textcolor{olive}{孙晓庆}\\
    \quad 幻灯片制作~~\textcolor{olive}{孙晓庆}}
\institute[中国海洋大学]{\small\textcolor{violet}{中国海洋大学~~信息科学与工程学院}}
\date{2013~年~9~月~27~日}
%\titlegraphic{\vspace{-6em}\includegraphics[height=7cm]{ouc}\vspace{-6em}}
\frame{ \titlepage }
%%----------------------------------------------------------
\section*{目录}
\frame{\frametitle{目录}\tableofcontents}
%%----------------------------------------------------------
\section{Solution of Nonlinear Equation}

\subsection{Bisection (Interval Halving) Method} %如果你想书签不出现问题,请不要用\XeTeX
                                 %这类复杂的指令,直接写XeTeX吧
\begin{frame}
\frametitle{bisection method}
\begin{itemize}
\item Intermediate-Value Theorem:If $f$ is a continuous function on the interval $[a,b]$ and if $f(a)f(b)<0$, then $f$ must have a zero in $(a,b)$. 
\item The process of bisection method:\\
If $f(a)f(b)<0$, then $c=(a+b)/2$ \\
If $f(a)f(c)<0$, then $f$ has a zero in $[a,c]$, then $b\leftarrow c$\\
If $f(b)f(c)<0$, then $f$ has a zero in $[c,b]$, then $a\leftarrow c$\\
If $f(a)f(c)=0$, then $c$ is the zero of $f$\\
repeat this process
\item The bisection method finds one zero but not all the zeros in the interval $[a,b]$.
\end{itemize}
\end{frame}
           
% \XeTeXpicfile "./logo.jpg" xscaled 100 yscaled 100 %插图也没有问



\begin{frame}
\frametitle{Bisection Algorithm}
\begin{itemize}
\item \textbf{Bisection pseudocode need some additional explanation:}\\
First,$c\leftarrow a+(b-a)/2$ rather than $c\leftarrow (a+b)/2$\\
second,$sign(f(c))\neq sign(f(a))$  rather than $f(a)f(c)<0$
\item \textbf{three stopping criteria} \\
M give the maximum number of steps that present the computation going into an infinite loop.\\
When the value of $f(c)$ is small enough,the calculation can be stopped.\\
When $b-a$ is small enough, the calculation can be stopped.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{The bisection algorithm can be written as follows}
\begin{itemize}
\item  input $a$, $b$, $M$, $\delta$, $\varepsilon$\\
$u\leftarrow f(a)$\\
$v\leftarrow f(b)$\\
$e\leftarrow (b-a)$\\
output $a$,$b$,$u$,$v$\\
If $sign(u)=sign(v)$ then stop\\
for $k=1$ to $M$ do\\
$e\leftarrow e/2$\\
$c\leftarrow a+e$\\
$w\leftarrow f(c)$\\
output $k$,$c$,$w$,$e$\\
If $|e|<\delta$ or $|w|<\varepsilon$ then stop\\
\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
\item If $sign(w)\neq sign(u)$ then\\
$b\leftarrow c$\\
$v\leftarrow w$\\
else\\
$a\leftarrow c$\\
$u\leftarrow w$\\
end if\\
end do\\
\end{itemize}
\end{frame}





\begin{frame}
\frametitle{EXAMPLE 1}
\begin{itemize}
\item Use the bisection method to find the root of the equation $e^{x}=sinx$ closest to 0.
\end{itemize}
\lstinputlisting{./BisectionE1/equation.m}
\lstinputlisting{./BisectionE1/bisectiontest.m}
\end{frame}

\begin{frame}
\frametitle{EXAMPLE 1}
\lstinputlisting{./BisectionE1/Bisection.m}  
\end{frame}


\begin{frame}
\frametitle{Error Analysis}
\begin{itemize}
\item Let us denote the successive intervals that arise in the process by $[a_{0},b_{0}]$,$[a_{1},b_{1}]$, and so no. 
\begin{displaymath}
a_{0}\leq a_{1}\leq a_{2}\leq a_{3}\leq...\leq b_{0}
\end{displaymath}
\begin{displaymath}
b_{0}\geq b_{1}\geq b_{2}\geq b_{3}\geq...\geq a_{0}
\end{displaymath}
\begin{displaymath}
b_{n+1}-a_{n+1}=1/2(b_{n}-a_{n})   (n\geq 0)    (1)
\end{displaymath}
If we apply Equation$(1)$ repeatedly, we find that
\begin{displaymath}
b_{n}-a_{n}=2^{-n}(b_{0}-a_{0})
\end{displaymath}
\begin{displaymath}
\lim_{n \to \infty}b_{n}-\lim_{n \to \infty}a_{n}=\lim_{n \to \infty}2^{-n}(b_{0}-a_{0})=0
\end{displaymath}
\begin{displaymath}
r=\lim_{n \to \infty}a_{n}=\lim_{n \to \infty}b_{n}
\end{displaymath}
\end{itemize}
\end{frame}


\begin{frame}
\begin{itemize}
\item then,by taking a limit in the inequality $f(a_{n})f(b_{n})\leq 0$, we obtain $[f(r)]^{2}\leq 0$, whence $f(r)=0$ 
\newline
The best estimate of the root at this stage is not $a_{n}$ or $b_{n}$ but the midpoint of the interval: $c_{n}=(a_{n}+b_{n})/2$
\newline
The error is the bounded as follows:
\begin{displaymath}
|r-c_{n}|\leq 1/2(b_{n}-a_{n})=2^{-(n+1)}(b_{0}-a_{0})
\end{displaymath}
\end{itemize}
\end{frame}



%\subsection{Simple Roots}
\begin{frame}
\frametitle{Theorem on bisection method}
\theoremstyle{plain}
\newtheorem{theorem}{THEOREM}
\begin{theorem}[Theorem on bisection method]
 If $[a_{0},b_{0}]$,$[a_{1},b_{1}]$,...,$[a_{n},b_{n}]$,...denote the intervals in the bisection method, then the limits $\lim_{n \to \infty}a_{n}$ and $\lim_{n \to \infty}b_{n}$ exist, are equal,and repredsent a zero of $f$. If $r=\lim_{n \to \infty}c_{n}$ and $c_{n}=1/2(a_{n}+b_{n})$,then
\begin{displaymath}
|r-c_{n}|\leq 2^{-(n+1)}(b_{0}-a_{0})
\end{displaymath}
\end{theorem} 
\end{frame}


%\subsection{Multiple Roots}
\begin{frame}
\frametitle{EXAMPLE 2}
\begin{itemize}
\item Suppose that the bisection method is started with the interval $[50,63]$.How many steps should be taken to compute a root with relative accuracy of one part in $10^{-12}$?
\newline
relative accuracy means that
\begin{displaymath}
|r-c_{n}|/|r|\leq 10^{-12}
\end{displaymath}
We know that $r\geq 50$,so
\begin{displaymath}
|r-c_{n}|/50\leq 10^{-12}
\end{displaymath}
\begin{displaymath}
|r-c_{n}|\leq2^{-(n+1)}(63-50)
\end{displaymath}
\begin{displaymath}
2^{-(n+1)}*(13/15)\leq 10^{-12}
\end{displaymath}
We conclude that $n\geq 37$
\end{itemize}
\end{frame}


\subsection{Newton's Method}
\begin{frame}
\frametitle{Newton's Method}
\begin{itemize}
\item We have a fnction $f$ whose zeros are to be determined numerically. Let $r$ be a zero of $f$ and let $x$ be an approximation to $r$. If $f''$ exists and is continuous, then by Taylor's theorem,
\begin{displaymath}
0=f(r)=f(x+h)=f(x)+hf'(x)+O(h^2)
\end{displaymath}
where $h=r-x$, ignore the $O(h^2)$, then $h=-f(x)/f'(x)$
\begin{displaymath}
r=h+x=x-f(x)/f'(x)
\end{displaymath}
Newton's method begins with an estimate $x_{0}$ of $r$ and then defines inductively
\begin{displaymath}
x_{n+1}=x_{n}-f(x_{n})/f'(x_{n})   (n\geq 0)
\end{displaymath}
\end{itemize}
\end{frame}




\begin{frame}
\frametitle{Newton's Algorithm}
\begin{itemize}
\item input $x_0$, $M$, $\delta$, $\varepsilon$\\
$v\leftarrow f(x_{0})$\\
output 0,$x_{0}$,$v$\\
If $|v|<\varepsilon$ then stop\\
for $k=1$ to $M$ do\\
$x_{1}\leftarrow x_{0}-v/f'(x_{0})$\\
$v\leftarrow f(x_{1})$\\
output $k$,$x_{1}$,$v$\\
If $|x_{1}-x_{0}|<\delta$ or $|v|<\varepsilon$ then stop\\
$x_{0}\leftarrow x_{1}$\\
end do
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{EXAMPLE 3}
\begin{itemize}
\item Use Newton's method,to find the negative zero of the function $f(x)=e^{x}-1.5-tan^{-1}x$
\end{itemize}
\lstinputlisting{./newtonE3/newf.m}
\lstinputlisting{./newtonE3/newdf.m}
\lstinputlisting{./newtonE3/newtontest.m}
\end{frame}


\begin{frame}
\frametitle{EXAMPLE 3}
\lstinputlisting{./newtonE3/newton.m}
\end{frame}


\begin{frame}
\frametitle{Graphical Interpretation}
\begin{itemize}
\item Newton's method involves linearizing the function.Replace $f$ by the first two in his Taylor series.
\begin{displaymath}
f(x)=f(c)+f'(c)(x-c)+1/2f''(c)(x-c)^{2}+...
\end{displaymath}
then the linearization (at c) produces the linear function:
\begin{displaymath}
l(x)=f(c)+f'(c)(x-c)
\end{displaymath}
$l$ is a good approximation to f in the vicinity of $c$, and we have $l(c)=f(c)$ and $l'(c)=f'(c)$ 
\end{itemize}
\end{frame}

\begin{frame}
\XeTeXpicfile "./Newton.png" xscaled 400 yscaled 400   
\end{frame}



\begin{frame}
\frametitle{Error Analysis}
\begin{itemize}
\item Now we shall analyze the errors in Newton's method.
\begin{displaymath}
e_{n}=x_{n}-r
\end{displaymath}
Let us assume that $f''$ is continuous and $r$ is a simple zero of $f$, so that $f(r)=0\neq f'(r)$. From the definition of the Newton iteration, We have
\begin{displaymath}
e_{n+1}=x_{n+1}-r=x_{n}-\frac{f(x_{n})}{f'(x_{n})}-r=e_{n}-\frac{f(x_{n})}{f'(x_{n})}=\frac{{e_{n}f'(x_{n})-f(x_{n})}}{f'(x_{n})}
\end{displaymath}
\begin{displaymath}
0=f(r)=f(x_{n}-e_{n})=f(x_{n})-e_{n}f'(x_{n})+\frac{1}{2}e_{n}^{2}f''(\xi_{n})
\end{displaymath}
\begin{displaymath}
e_{n}f'(x_{n})-f(x_{n})=\frac{1}{2}f''(\xi_{n})e_{n}^{2}
\end{displaymath}
\begin{displaymath}
e_{n+1}=\frac{1}{2}\frac{f''(\xi_{n})}{f'(x_{n})}e_{n}^{2}\approx \frac{1}{2}\frac{f''(r)}{f'(r)}e_{n}^{2}=Ce_{n}^{2}
\end{displaymath}
\end{itemize}
\end{frame}
  
\begin{frame}
\frametitle{Theorem on Newton's Method}
\begin{theorem}[Theorem on Newton's Method]
Let $f''$ be continuous and let $r$ be a simple zero of $f$. Then there is a neighborhood of $r$ and a constant $C$ such that if Newton's method is started in that neighborhood, the successive points become steadily closer to $r$ and satisfy 
\begin{displaymath}
|x_{n+1}-r|\le C(x_{n}-r)^{2}
\end{displaymath}
\end{theorem}
\begin{itemize}
\item In some situations Newton's iteration can be guaranteed to converge from an arbitary starting point.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Theorem on Newton's Method for a Convex Function}

\begin{theorem}[Theorem on Newton's Method for a Convex Function]
 If $f$ belongs to $C^{2}(R)$, is increasing, is convex, and has a zero, then the zero is unique, and the Newton iteration will converge to it from any starting point. \\
\end{theorem}
\begin{itemize}
\item proof: $f$ is convex $\rightarrow$ $f''(x)>0$, $f$ is increasing $\rightarrow$ $f'>0$ on the $R$\\
By Equation,$e_{n+1}=\frac{1}{2}\frac{f''(\xi_{n})}{f'(x_{n})}e_{n}^{2}$, $e_{n+1}>0$\\
$e_{n+1}=x_{n+1}-r$ $\rightarrow$ $x_{n}>r$ for $n\geq1$\\
$f$ is increasing, $f(x_{n})>f(r)=0$. by Equation $e_{n+1}=e_{n}-\frac{f(x_{n})}{f'(x_{n})}$, $e_{n+1}<e_{n}$\\
Thus ,the sequences $[e_{n}]$ and $[x_{n}]$ are decreasing and bounded below $(0,r)$. Therefore, the limits $e^{*}=\lim_{n \to \infty}e_{n}$ and $x^{*}=\lim_{n \to \infty}x_{n}$ exist. $e^{*}=e^{*}-\frac{f(x^{*})}{f'(x^{*})}$, Whence $f(x^{*})=0$ and $x^{*}=r$. 
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Implicit Functions}
\begin{itemize}
\item For the equation $G(x,y)=0$,If $x$ is prescribed, the equation $G(x,y)=0$ can be solved for $y$ using Newton's method. Form a suitable staring point $y_{0}$, we define $y_{1},y_{2},...$ by, this method can be used to construct a table of the function $y(x)$. \\
\begin{displaymath}
y_{k+1}=y_{k}-\frac {G(x,y_{k})}{{\frac{\partial G}{\partial y}}{(x,y_{k})}}
\end{displaymath}
If the table contains an entry $(x_{n}.y_{n})$, we can start the Newton iteration with $(x_{n+1}, y_{n})$, the result will the value $y_{n+1}$.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{EXAMPLE 4}
\begin{itemize}
\item Produce a table of $x$ versus $y$, where $y$ is defined implicitly as a function of $x$. Use $G(x,y)=3x^{7}+2y^{5}-x^{3}+y^{3}-3$ and start at $x=0$, proceeding in steps of $0.1$ to $x=10$.
\lstinputlisting{./newtonE4/F.m}
\lstinputlisting{./newtonE4/Fy.m}
\lstinputlisting{./newtonE4/newton4test.m}
%\begin{lstlisting}
%for i=1:3
%\end{lstlisting}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{EXAMPLE 4}
\lstinputlisting{./newtonE4/newton4.m}
\end{frame}

\begin{frame}
\frametitle{Systems of Nonlinear Equations}
\begin{itemize}
\item Newton's method for systems of nonlinear equations follows \textbf{linearize} and \textbf{solve},let us illustrate with a pair of equations involving two variables:
\begin{displaymath}
\left\{ \begin{array}{ll}
f_{1}(x_{1},x_{2})=0\\
f_{2}(x_{1},x_{2})=0
\end{array}\right.
\end{displaymath}
linear terms in the Tayor expansion 
\begin{displaymath}
\left\{ \begin{array}{ll} 
0=f_{1}(x_{1}+h_{1},x_{2}+h_{2})\approx f_{1}(x_{1},x_{2})+h_{1}\frac {\partial f_{1}}{\partial x_{1}}+h_{2}\frac{\partial f_{1}}{\partial x_{2}}\\ 
0=f_{2}(x_{1}+h_{1},x_{2}+h_{2})\approx f_{2}(x_{1},x_{2})+h_{1}\frac {\partial f_{2}}{\partial x_{1}}+h_{2}\frac{\partial f_{2}}{\partial x_{2}}
\end{array}\right.
\end{displaymath}
J is the \textbf{Jacobian matrix} of $f_{1}$ and $f_{2}$:
\begin{displaymath}
\mathbf{J} =
\left[ \begin{array}{ccc}
\frac{\partial f_{1}}{\partial x_{1}}&\frac{\partial f_{1}}{\partial x_{2}} \\
\frac{\partial f_{2}}{\partial x_{1}}&\frac{\partial f_{2}}{\partial x_{2}} \end{array} \right]
\end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
\item the solution is
\begin{displaymath}
\left[ \begin{array}{ccc}
h_{1}\\h_{2}\end{array}\right]=-J^{-1}\left[\begin{array}{ccc}f_{1}(x_{1},x_{2})\\f_{2}(x_{1},x_{2})\end{array} \right]
\end{displaymath}
Newton's method for two nonlinear equations in two variables is
\begin{displaymath}
\left[ \begin{array}{ccc}
x_{1}^{(k+1)}\\x_{2}^{(k+1)}\end{array}\right]=\left[\begin{array}{ccc}x_{1}^{(k)}\\x_{2}^{(k)}\end{array} \right]+\left[\begin{array}{ccc}h_{1}^{(k)}\\h_{2}^{(k)}\end{array} \right]
\end{displaymath}
\end{itemize}
\end{frame}


\subsection{Secant Method}
\begin{frame}
\frametitle{Secant Method}
\begin{itemize}
\item \textbf{The drawback of Newton's method} is need the derivative of the function at zero.
\item How to slove ?\\
1.Steffensen's iteration $x_{n+1}=x_{n}-\frac{{[f(x_{n})]}^2}{{f(x_{n}+f(x_{n}))}-f(x_{n})}$\\
2.Scant Method
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Secant Method}
\begin{itemize}
\item The Newton iteration is $x_{n+1}=x_{n}-\frac{f(x_{n})}{f'(x_{n})}$, replace $f'(x_{n})$ by a \textbf{difference quotient},such as
\begin{displaymath}
f'(x_{n})\approx \frac{f(x_{n})-f(x_{n-1})}{x_{n}-x_{n-1}}
\end{displaymath}
\begin{displaymath}
x_{n+1}=x_{n}-f(x_{n})[\frac{x_{n}-x_{n-1}}{f(x_{n})-f(x_{n-1})}]
\end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Secant Algorithm}
\begin{itemize}
\item input $a$, $b$, $M$, $\delta$, $\varepsilon$
$fa\leftarrow f(a)$; $fb\leftarrow f(b)$\\
output 0,$a$,$fa$\\
output 1,$b$,$fb$\\
for $k=2$ to $M$ do\\
If $|fa|>|fb|$ then \\
$a\leftrightarrow b$; $fa\leftrightarrow fb$\\
end if\\
$s\leftarrow (b-a)/(fb-fa)$\\
$b\leftarrow a$\\
$fb\leftarrow fa$\\
$a\leftarrow a-fa*s$\\
$fa\leftarrow f(a)$\\
output k,a,fa\\
If $|fa|<\delta$ or $|b-a|<\varepsilon$ then stop\\
end do
\end{itemize}
\end{frame}



%\subsection{Secant Method}
\begin{frame}
\frametitle{EXAMPLE 5}
 Use the secant method to find a zero of the function  $f(x)=x^{3}-sinhx+4x^{2}+6x+9$
\lstinputlisting{./secantE5/sca.m}
\lstinputlisting{./secantE5/secanttest.m}
\end{frame}


\begin{frame}
\frametitle{EXAMPLE 5}
\lstinputlisting{./secantE5/scant.m}
\end{frame}


\begin{frame}
\frametitle{Error Analysis}
\begin{itemize}
\item $|e_{n+1}|\thickapprox A|e_{n}|^{(1+\sqrt{5})/2}$
\item  since $(1+\sqrt{5})/2\thickapprox 1.62<2$, the rapidity of convergence of the secant method is not as good as Newton's method but is better than the bisection method.
\end{itemize}
\end{frame}






\end{document}
